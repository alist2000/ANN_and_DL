{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "z4oiAD9W8sjX",
        "outputId": "46c800df-ed51-45fc-f921-7b6c48c8a7ec"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2cb898ab-0cf4-4f2c-b424-989a3fca1c4a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2cb898ab-0cf4-4f2c-b424-989a3fca1c4a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Normalized_WT5.txt to Normalized_WT5.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-fd73ed387e22>:11: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  data = pd.read_csv(\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Upload the file\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Upload the dataset\n",
        "uploaded = files.upload()  # This will prompt you to upload the TXT file\n",
        "# Load the data into a DataFrame\n",
        "file_name = list(uploaded.keys())[0]\n",
        "data = pd.read_csv(\n",
        "    file_name,\n",
        "    delim_whitespace=True,  # or sep=\"\\t\", depending on your file\n",
        "    header=0,               # Adjust if your header is on a different row\n",
        "    skiprows=0              # Adjust if needed\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# General form for slime mould algorithm\n",
        "def slime_mould_algorithm(obj_func, N=30, max_iter=100, lb=-10, ub=10, dim=5):\n",
        "    \"\"\"\n",
        "    Implementation of the Slime Mould Algorithm (SMA).\n",
        "\n",
        "    Args:\n",
        "        obj_func (function): The objective function to minimize.\n",
        "        N (int): Number of slime moulds (population size).\n",
        "        max_iter (int): Maximum number of iterations.\n",
        "        lb (float or np.array): Lower boundary of the search space.\n",
        "        ub (float or np.array): Upper boundary of the search space.\n",
        "        dim (int): Dimensionality of the search space.\n",
        "\n",
        "    Returns:\n",
        "        best_position (np.array): Best solution found.\n",
        "        best_fitness (float): Fitness value of the best solution.\n",
        "    \"\"\"\n",
        "    # Initialize population\n",
        "    population = np.random.uniform(lb, ub, (N, dim))\n",
        "    fitness = np.apply_along_axis(obj_func, 1, population)\n",
        "\n",
        "    # Initialize best solution\n",
        "    best_idx = np.argmin(fitness)\n",
        "    best_position = population[best_idx]\n",
        "    best_fitness = fitness[best_idx]\n",
        "\n",
        "    for t in range(max_iter):\n",
        "        # Rank population and assign weights\n",
        "        sorted_indices = np.argsort(fitness)\n",
        "        population = population[sorted_indices]\n",
        "        fitness = fitness[sorted_indices]\n",
        "\n",
        "        # Update best position\n",
        "        if fitness[0] < best_fitness:\n",
        "            best_position = population[0]\n",
        "            best_fitness = fitness[0]\n",
        "\n",
        "        # Calculate weights\n",
        "        W = 1 + np.log(1 + (fitness[-1] - fitness) / (fitness[-1] - fitness[0] + 1e-10))\n",
        "\n",
        "        # Update positions\n",
        "        for i in range(N):\n",
        "            r = np.random.rand()\n",
        "            vb = np.random.uniform(-1, 1)\n",
        "            vc = np.random.uniform(0, 1)\n",
        "            if r < vc:\n",
        "                # Exploitation phase\n",
        "                new_position = population[0] + vb * (W[i] * (population[i] - population[0]))\n",
        "            else:\n",
        "                # Exploration phase\n",
        "                new_position = np.random.uniform(lb, ub, dim)\n",
        "\n",
        "            # Boundary control\n",
        "            population[i] = np.clip(new_position, lb, ub)\n",
        "\n",
        "        # Evaluate fitness of updated population\n",
        "        fitness = np.apply_along_axis(obj_func, 1, population)\n",
        "\n",
        "    return best_position, best_fitness\n",
        "\n",
        "\n",
        "# Example: Sphere function as the objective\n",
        "def sphere_function(x):\n",
        "    return np.sum(x**2)\n",
        "\n",
        "# Run SMA\n",
        "best_position, best_fitness = slime_mould_algorithm(sphere_function, N=30, max_iter=100, lb=-5, ub=5, dim=10)\n",
        "\n",
        "print(\"Best Position:\", best_position)\n",
        "print(\"Best Fitness:\", best_fitness)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIral1Od1tf0",
        "outputId": "881d8cff-1e5b-464b-ee58-7b9b13595ef1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Position: [ 1.21133407 -3.35736336  3.45981292  3.12402484 -0.23516792  3.52729965\n",
            " -2.5285493  -4.82434544  1.19207925 -0.42090593]\n",
            "Best Fitness: 3.3661506511051416\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_gWtY3q8xmM",
        "outputId": "289874be-4346-4990-ed0e-af66ecb71971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Column Names: Index(['Sequence No.', 'V', 'D', 'air density', 'Humidity', 'I', 'S_a', 'S_b',\n",
            "       'y (% relative to rated power)'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Select the first 1440 rows and extract relevant columns\n",
        "data = data.iloc[:1440]  # Select only the first 1440 rows\n",
        "time = np.arange(1, 1441)  # Generate time steps (1 to 1440)\n",
        "# Clean column names\n",
        "data.columns = data.columns.str.strip()  # Remove leading and trailing whitespaces\n",
        "print(\"Cleaned Column Names:\", data.columns)  # Check cleaned column names\n",
        "\n",
        "# Access the 'y' column\n",
        "power = data[\"y (% relative to rated power)\"]  # Ensure this matches the cleaned column name\n",
        "\n",
        "\n",
        "# Step 3: Plot Figure 6 - Offshore Wind Power Timing Diagram\n",
        "train_size = int(0.8 * len(data))  # 80% train, 20% test split\n",
        "train_power = power[:train_size]\n",
        "test_power = power[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bzb7n2--85bR"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Reshape\n",
        "\n",
        "class Autoencoder:\n",
        "    def __init__(self, window_size, latent_dim):\n",
        "        \"\"\"\n",
        "        Initialize the Autoencoder class.\n",
        "        Args:\n",
        "            window_size (int): Number of time steps in each sequence (input dimension).\n",
        "            latent_dim (int): Size of the latent space (latent dimension).\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        self.latent_dim = latent_dim\n",
        "        self.autoencoder = None\n",
        "        self.encoder = None\n",
        "        self.decoder = None\n",
        "    def build(self):\n",
        "        \"\"\"\n",
        "        Build the Autoencoder, Encoder, and Decoder models.\n",
        "        \"\"\"\n",
        "        # Encoder\n",
        "        input_layer = Input(shape=(self.window_size, 1), name=\"Input_Layer\")\n",
        "        flattened = Flatten(name=\"Flatten_Layer\")(input_layer)  # Flatten time-series input\n",
        "        hidden1 = Dense(128, activation='relu', name=\"Hidden_Layer_1\")(flattened)\n",
        "        hidden2 = Dense(64, activation='relu', name=\"Hidden_Layer_2\")(hidden1)\n",
        "        latent_layer = Dense(self.latent_dim, activation='relu', name=\"Latent_Layer\")(hidden2)\n",
        "        # Decoder\n",
        "        hidden3 = Dense(64, activation='relu', name=\"Decoder_Layer_1\")(latent_layer)\n",
        "        hidden4 = Dense(128, activation='relu', name=\"Decoder_Layer_2\")(hidden3)\n",
        "        output_flat = Dense(self.window_size, activation='linear', name=\"Output_Flat\")(hidden4)\n",
        "        output_layer = Reshape((self.window_size, 1), name=\"Output_Reshape\")(output_flat)\n",
        "        # Autoencoder Model\n",
        "        self.autoencoder = Model(inputs=input_layer, outputs=output_layer, name=\"Autoencoder\")\n",
        "        # Encoder Model\n",
        "        self.encoder = Model(inputs=input_layer, outputs=latent_layer, name=\"Encoder\")\n",
        "\n",
        "        # Decoder Model\n",
        "        encoded_input = Input(shape=(self.latent_dim,), name=\"Encoded_Input\")\n",
        "        decoder_hidden1 = self.autoencoder.get_layer(\"Decoder_Layer_1\")(encoded_input)\n",
        "        decoder_hidden2 = self.autoencoder.get_layer(\"Decoder_Layer_2\")(decoder_hidden1)\n",
        "        decoder_flat = self.autoencoder.get_layer(\"Output_Flat\")(decoder_hidden2)\n",
        "        decoder_output = self.autoencoder.get_layer(\"Output_Reshape\")(decoder_flat)\n",
        "        self.decoder = Model(inputs=encoded_input, outputs=decoder_output, name=\"Decoder\")\n",
        "\n",
        "    def compile(self, optimizer='adam', loss='mse'):\n",
        "        \"\"\"\n",
        "        Compile the Autoencoder model.\n",
        "\n",
        "        Args:\n",
        "            optimizer (str): Optimizer for training (default: 'adam').\n",
        "            loss (str): Loss function to minimize (default: 'mse').\n",
        "        \"\"\"\n",
        "        if not self.autoencoder:\n",
        "            raise ValueError(\"The model must be built before compiling.\")\n",
        "        self.autoencoder.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "    def train(self, x_train, epochs=100, batch_size=32, shuffle=True, validation_split=0.1):\n",
        "        \"\"\"\n",
        "        Train the Autoencoder model.\n",
        "        Args:\n",
        "            x_train (np.array): Training input data (e.g., sequences of time steps).\n",
        "            epochs (int): Number of epochs to train (default: 100).\n",
        "            batch_size (int): Batch size for training (default: 16).\n",
        "            shuffle (bool): Whether to shuffle the training data (default: True).\n",
        "            validation_split (float): Fraction of data for validation (default: 0.1).\n",
        "\n",
        "        Returns:\n",
        "            History object: Contains training history.\n",
        "        \"\"\"\n",
        "        if not self.autoencoder:\n",
        "            raise ValueError(\"The model must be built and compiled before training.\")\n",
        "        return self.autoencoder.fit(\n",
        "            x_train, x_train,  # Input and target are the same for autoencoders\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=shuffle,\n",
        "            validation_split=validation_split\n",
        "        )\n",
        "    def summary(self):\n",
        "        \"\"\"\n",
        "        Print the summary of the Autoencoder model.\n",
        "        \"\"\"\n",
        "        if not self.autoencoder:\n",
        "            raise ValueError(\"The model must be built before accessing the summary.\")\n",
        "        self.autoencoder.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O-Poik7X8_65",
        "outputId": "23f44258-a664-4f85-f2a4-b6ca18a4faea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - loss: 2269.3003 - val_loss: 116.1201\n",
            "Epoch 2/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 373.6405 - val_loss: 102.8658\n",
            "Epoch 3/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 186.6708 - val_loss: 88.2368\n",
            "Epoch 4/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 113.1669 - val_loss: 69.0535\n",
            "Epoch 5/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 85.4543 - val_loss: 53.8679\n",
            "Epoch 6/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 67.8037 - val_loss: 40.3808\n",
            "Epoch 7/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 54.2087 - val_loss: 24.1823\n",
            "Epoch 8/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 40.9080 - val_loss: 22.4475\n",
            "Epoch 9/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 32.3666 - val_loss: 18.2494\n",
            "Epoch 10/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.9539 - val_loss: 19.7642\n",
            "Epoch 11/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.4188 - val_loss: 19.5947\n",
            "Epoch 12/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.5105 - val_loss: 27.7348\n",
            "Epoch 13/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.1130 - val_loss: 19.6405\n",
            "Epoch 14/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.5419 - val_loss: 17.6862\n",
            "Epoch 15/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.3056 - val_loss: 15.7522\n",
            "Epoch 16/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.0297 - val_loss: 17.2524\n",
            "Epoch 17/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.2756 - val_loss: 14.8215\n",
            "Epoch 18/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.4139 - val_loss: 13.6283\n",
            "Epoch 19/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.6835 - val_loss: 14.4062\n",
            "Epoch 20/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 22.1512 - val_loss: 18.5823\n",
            "Epoch 21/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.0207 - val_loss: 12.3357\n",
            "Epoch 22/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1150 - val_loss: 12.3062\n",
            "Epoch 23/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.6643 - val_loss: 12.8744\n",
            "Epoch 24/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3229 - val_loss: 15.3895\n",
            "Epoch 25/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 18.1436 - val_loss: 13.2267\n",
            "Epoch 26/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.5874 - val_loss: 11.6994\n",
            "Epoch 27/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.0870 - val_loss: 11.8845\n",
            "Epoch 28/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 16.2696 - val_loss: 11.5012\n",
            "Epoch 29/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 14.7097 - val_loss: 11.0572\n",
            "Epoch 30/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.8076 - val_loss: 7.8622\n",
            "Epoch 31/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.8040 - val_loss: 8.8565\n",
            "Epoch 32/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6883 - val_loss: 7.5588\n",
            "Epoch 33/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.5037 - val_loss: 8.6307\n",
            "Epoch 34/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.8321 - val_loss: 9.8446\n",
            "Epoch 35/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 13.7249 - val_loss: 9.6082\n",
            "Epoch 36/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.4295 - val_loss: 7.0009\n",
            "Epoch 37/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8567 - val_loss: 6.2875\n",
            "Epoch 38/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.8601 - val_loss: 6.2123\n",
            "Epoch 39/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 11.1650 - val_loss: 7.1184\n",
            "Epoch 40/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.4846 - val_loss: 7.1066\n",
            "Epoch 41/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.0942 - val_loss: 10.5293\n",
            "Epoch 42/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.6202 - val_loss: 6.9144\n",
            "Epoch 43/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.8970 - val_loss: 9.2233\n",
            "Epoch 44/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.3422 - val_loss: 6.6365\n",
            "Epoch 45/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 12.4472 - val_loss: 7.5598\n",
            "Epoch 46/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.8176 - val_loss: 6.4894\n",
            "Epoch 47/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.1157 - val_loss: 6.0970\n",
            "Epoch 48/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 11.0159 - val_loss: 6.7339\n",
            "Epoch 49/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.6636 - val_loss: 6.5830\n",
            "Epoch 50/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9940 - val_loss: 11.0417\n",
            "Epoch 51/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.9118 - val_loss: 7.7040\n",
            "Epoch 52/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 15.9689 - val_loss: 6.9677\n",
            "Epoch 53/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6950 - val_loss: 6.3760\n",
            "Epoch 54/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6906 - val_loss: 6.5229\n",
            "Epoch 55/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2450 - val_loss: 6.9631\n",
            "Epoch 56/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0288 - val_loss: 7.1970\n",
            "Epoch 57/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6206 - val_loss: 6.7477\n",
            "Epoch 58/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.6843 - val_loss: 6.9238\n",
            "Epoch 59/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.8508 - val_loss: 27.4856\n",
            "Epoch 60/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 12.9209 - val_loss: 6.6691\n",
            "Epoch 61/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0772 - val_loss: 8.2151\n",
            "Epoch 62/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5886 - val_loss: 7.2937\n",
            "Epoch 63/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.0646 - val_loss: 9.1924\n",
            "Epoch 64/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.6181 - val_loss: 7.4709\n",
            "Epoch 65/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.5101 - val_loss: 8.5678\n",
            "Epoch 66/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.3743 - val_loss: 6.3795\n",
            "Epoch 67/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5538 - val_loss: 6.4194\n",
            "Epoch 68/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7538 - val_loss: 6.7170\n",
            "Epoch 69/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6922 - val_loss: 8.3234\n",
            "Epoch 70/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7556 - val_loss: 8.1238\n",
            "Epoch 71/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2732 - val_loss: 8.8847\n",
            "Epoch 72/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.7039 - val_loss: 6.7483\n",
            "Epoch 73/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5707 - val_loss: 8.8843\n",
            "Epoch 74/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1180 - val_loss: 15.1277\n",
            "Epoch 75/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 11.3471 - val_loss: 7.2422\n",
            "Epoch 76/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6039 - val_loss: 6.8758\n",
            "Epoch 77/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.8866 - val_loss: 7.8583\n",
            "Epoch 78/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6385 - val_loss: 9.0527\n",
            "Epoch 79/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.6987 - val_loss: 7.6190\n",
            "Epoch 80/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.5521 - val_loss: 8.3547\n",
            "Epoch 81/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.9402 - val_loss: 7.6885\n",
            "Epoch 82/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.0144 - val_loss: 7.9830\n",
            "Epoch 83/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7411 - val_loss: 7.7922\n",
            "Epoch 84/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.3298 - val_loss: 7.0759\n",
            "Epoch 85/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.5756 - val_loss: 7.5433\n",
            "Epoch 86/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.9090 - val_loss: 7.6340\n",
            "Epoch 87/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.1572 - val_loss: 8.1500\n",
            "Epoch 88/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7238 - val_loss: 7.6394\n",
            "Epoch 89/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 8.6202 - val_loss: 9.3900\n",
            "Epoch 90/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 10.2698 - val_loss: 7.4295\n",
            "Epoch 91/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.1951 - val_loss: 7.7535\n",
            "Epoch 92/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.4497 - val_loss: 7.8176\n",
            "Epoch 93/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9271 - val_loss: 7.4698\n",
            "Epoch 94/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8353 - val_loss: 7.8891\n",
            "Epoch 95/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.9600 - val_loss: 7.8675\n",
            "Epoch 96/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 9.3002 - val_loss: 15.9045\n",
            "Epoch 97/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 10.5366 - val_loss: 7.7738\n",
            "Epoch 98/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 8.8591 - val_loss: 6.7213\n",
            "Epoch 99/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 9.2216 - val_loss: 11.1971\n",
            "Epoch 100/100\n",
            "\u001b[1m73/73\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9.7806 - val_loss: 7.2950\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"Autoencoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"Autoencoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Flatten_Layer (\u001b[38;5;33mFlatten\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden_Layer_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m18,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden_Layer_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Latent_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)                  │           \u001b[38;5;34m1,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Decoder_Layer_1 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m1,088\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Decoder_Layer_2 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Flat (\u001b[38;5;33mDense\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m)                 │          \u001b[38;5;34m18,576\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Reshape (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m144\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Flatten_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Hidden_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Latent_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Decoder_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,088</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Decoder_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Flat (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,576</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m167,522\u001b[0m (654.39 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">167,522</span> (654.39 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m55,840\u001b[0m (218.12 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">55,840</span> (218.12 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m111,682\u001b[0m (436.26 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,682</span> (436.26 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m41/41\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        }
      ],
      "source": [
        "# Parameters\n",
        "window_size = 144  # Time steps in each sequence\n",
        "latent_dim = 16   # Size of the latent space\n",
        "\n",
        "def create_sliding_windows(data, window_size):\n",
        "    \"\"\"\n",
        "    Create sliding windows from the data.\n",
        "\n",
        "    Args:\n",
        "        data (np.array): Input data array (1D time-series).\n",
        "        window_size (int): Number of time steps in each window.\n",
        "\n",
        "    Returns:\n",
        "        np.array: Array of sliding windows with shape (num_samples, window_size, 1).\n",
        "    \"\"\"\n",
        "    windows = []\n",
        "    for i in range(len(data) - window_size + 1):\n",
        "        windows.append(data[i:i + window_size])\n",
        "    return np.array(windows).reshape(-1, window_size, 1)\n",
        "\n",
        "# Simulated input data (replace with your actual y column values)\n",
        "sliding_windows = create_sliding_windows(power, window_size)\n",
        "\n",
        "# Create and build the Autoencoder\n",
        "autoencoder_model = Autoencoder(window_size, latent_dim)\n",
        "autoencoder_model.build()\n",
        "\n",
        "# Compile the Autoencoder\n",
        "autoencoder_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the Autoencoder\n",
        "history = autoencoder_model.train(\n",
        "    x_train=sliding_windows,\n",
        "    epochs=100,\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    validation_split=0.1\n",
        ")\n",
        "\n",
        "# Display the model summary\n",
        "autoencoder_model.summary()\n",
        "\n",
        "# Use the trained Autoencoder to \"denoise\" (reconstruct) the data\n",
        "data_denoised = autoencoder_model.autoencoder.predict(sliding_windows)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "yJeedPTF9Eq3"
      },
      "outputs": [],
      "source": [
        "# Reconstruct the full denoised sequence from sliding windows\n",
        "denoised_full = np.zeros((1440,))\n",
        "count = np.zeros((1440,))  # Track the number of contributions for each time step\n",
        "\n",
        "# Aggregate overlapping windows\n",
        "for i in range(len(data_denoised)):\n",
        "    denoised_full[i:i + window_size] += data_denoised[i].flatten()\n",
        "    count[i:i + window_size] += 1\n",
        "\n",
        "# Average overlapping regions\n",
        "denoised_full /= count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbxBd0zG9aPY",
        "outputId": "39038847-ad96-4a7f-cad6-10f2f25a7506"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1440, 9)\n",
            "(1152, 9)\n",
            "Train size: 1152, Test size: 288\n",
            "X_train shape: (1008, 144, 8)\n",
            "y_train shape: (1008, 1)\n",
            "X_test shape: (144, 144, 8)\n",
            "y_test shape: (144, 1)\n",
            "Number of input features: 8\n",
            "Number of time steps in each input window: 144\n",
            "Forecast horizon: 1 (single-step prediction)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# ------------------------------\n",
        "# Step 1: Prepare Data\n",
        "# ------------------------------\n",
        "\n",
        "# PARAMETERS\n",
        "window_size = 144  # e.g., 144 time steps for input\n",
        "forecast_horizon = 1  # Predict 1 step ahead for single-step forecasting\n",
        "\n",
        "# Replace the last column with the denoised data\n",
        "data.iloc[:, -1] = denoised_full\n",
        "\n",
        "\n",
        "X_full = data.iloc[:, 1:].values  # All columns except the first and last\n",
        "y_full = data.iloc[:, -1].values   # Only the last column (target)\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Step 2: Normalize Features and Target\n",
        "# ---------------------------------------------------------\n",
        "# Normalize all features together, including the target column\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "data_scaled = scaler.fit_transform(data)  # Scale columns together\n",
        "print(data_scaled.shape)\n",
        "# Split into train and test sets (80% train, 20% test)\n",
        "train_ratio = 0.8\n",
        "train_size = int(train_ratio * len(data_scaled))\n",
        "data_train_scaled = data_scaled[:train_size]\n",
        "data_test_scaled = data_scaled[train_size:]\n",
        "print(data_train_scaled.shape)\n",
        "\n",
        "print(f\"Train size: {len(data_train_scaled)}, Test size: {len(data_test_scaled)}\")\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Step 3: Create Sliding Windows\n",
        "# ---------------------------------------------------------\n",
        "def create_sliding_windows(data, window_size, forecast_horizon):\n",
        "    \"\"\"\n",
        "    Create input (X) and output (y) arrays using sliding windows.\n",
        "\n",
        "    Args:\n",
        "        data (np.array): Scaled data (features and target together).\n",
        "        window_size (int): Number of time steps for input.\n",
        "        forecast_horizon (int): How many steps ahead to predict.\n",
        "\n",
        "    Returns:\n",
        "        (X, y): Arrays for input (X) and target (y).\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - window_size - forecast_horizon + 1):\n",
        "        X.append(data[i : i + window_size, :-1])  # All features except target\n",
        "        y.append(data[i + window_size : i + window_size + forecast_horizon, -1])  # Only target column\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "# Create sliding windows for train and test sets\n",
        "X_train, y_train = create_sliding_windows(data_train_scaled, window_size, forecast_horizon)\n",
        "X_test, y_test = create_sliding_windows(data_test_scaled, window_size, forecast_horizon)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)  # (samples, window_size, num_features)\n",
        "print(\"y_train shape:\", y_train.shape)  # (samples, forecast_horizon)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# Step 4: Summary of Input and Output\n",
        "# ---------------------------------------------------------\n",
        "# X_train will now contain all input features (except `y`) for the sliding window\n",
        "# y_train will contain the corresponding single-step target values (`y`)\n",
        "\n",
        "print(f\"Number of input features: {X_train.shape[-1]}\")\n",
        "print(f\"Number of time steps in each input window: {X_train.shape[1]}\")\n",
        "print(f\"Forecast horizon: {y_train.shape[-1]} (single-step prediction)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTNBvj48u3Wh"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZf-zJVvUKYo",
        "outputId": "48895b14-c70e-46fb-8e04-4e746d5b04c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1008, 144, 8)\n",
            "Number of training samples: 1008\n",
            "Number of testing samples: 144\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Dataset Preparation\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import math\n",
        "\n",
        "class WindPowerDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        \"\"\"\n",
        "        Initializes the dataset with input features and targets.\n",
        "\n",
        "        Args:\n",
        "            X (np.array): Input features of shape (num_samples, window_size).\n",
        "            y (np.array): Targets of shape (num_samples,).\n",
        "        \"\"\"\n",
        "        self.X = torch.tensor(X, dtype=torch.float32)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# Create PyTorch datasets\n",
        "train_dataset = WindPowerDataset(X_train, y_train.flatten())\n",
        "print(X_train.shape)\n",
        "test_dataset = WindPowerDataset(X_test, y_test.flatten())\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Number of training samples: {len(train_dataset)}\")\n",
        "print(f\"Number of testing samples: {len(test_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import math\n",
        "from typing import Dict, Tuple, List\n",
        "import time\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, max_len: int = 5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        # Ensure d_model is even\n",
        "        d_model = (d_model // 2) * 2\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Calculate number of dimensions for sin/cos\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Ensure proper dimensionality\n",
        "        pe[:, 0:d_model:2] = torch.sin(position * div_term)\n",
        "        pe[:, 1:d_model:2] = torch.cos(position * div_term)\n",
        "\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer('pe', pe)\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.pe[:x.size(0), :self.d_model]\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, input_dim, d_model=64, nhead=4, num_layers=3, dim_feedforward=128, max_len=144, dropout=0.1):\n",
        "        super(TransformerModel, self).__init__()\n",
        "\n",
        "        # Ensure d_model is divisible by nhead\n",
        "        d_model = (d_model // nhead) * nhead\n",
        "        # Ensure d_model is even for positional encoding\n",
        "        d_model = (d_model // 2) * 2\n",
        "\n",
        "        self.embedding = nn.Linear(input_dim, d_model)\n",
        "        self.pos_encoder = PositionalEncoding(d_model, max_len=max_len)\n",
        "        encoder_layers = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, num_layers=num_layers)\n",
        "        self.fc_out = nn.Linear(d_model, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = self.pos_encoder(x)\n",
        "        x = self.transformer_encoder(x)\n",
        "        x = x[-1, :, :]\n",
        "        return self.fc_out(x).squeeze()\n",
        "\n",
        "class HyperparameterOptimizer:\n",
        "    def __init__(self, train_loader, val_loader, input_dim: int, device: str = 'cuda'):\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.input_dim = input_dim\n",
        "        self.device = device\n",
        "\n",
        "        # Modified bounds to ensure even numbers and proper divisibility\n",
        "        self.param_bounds = {\n",
        "            'd_model': (32, 256),  # Will be adjusted to be divisible by nhead\n",
        "            'nhead': (2, 8),       # Must be power of 2\n",
        "            'num_layers': (1, 6),\n",
        "            'dim_feedforward': (64, 512),\n",
        "            'dropout': (0.0, 0.5),\n",
        "            'learning_rate': (1e-4, 1e-2)\n",
        "        }\n",
        "\n",
        "    def decode_solution(self, position: np.ndarray) -> Dict:\n",
        "        # Get number of heads first\n",
        "        nhead = 2 ** int(np.interp(position[1], [0, 1], [1, 3]))  # This gives 2, 4, or 8\n",
        "\n",
        "        # Get d_model and ensure it's divisible by nhead and even\n",
        "        d_model = int(np.interp(position[0], [0, 1], self.param_bounds['d_model']))\n",
        "        d_model = max(32, ((d_model // nhead) * nhead) // 2 * 2)\n",
        "\n",
        "        return {\n",
        "            'd_model': d_model,\n",
        "            'nhead': nhead,\n",
        "            'num_layers': int(np.interp(position[2], [0, 1], self.param_bounds['num_layers'])),\n",
        "            'dim_feedforward': int(np.interp(position[3], [0, 1], self.param_bounds['dim_feedforward'])),\n",
        "            'dropout': float(np.interp(position[4], [0, 1], self.param_bounds['dropout'])),\n",
        "            'learning_rate': float(np.interp(position[5], [0, 1], self.param_bounds['learning_rate']))\n",
        "        }\n",
        "\n",
        "    def evaluate_model(self, hyperparams: Dict, epochs: int = 5) -> float:\n",
        "        try:\n",
        "            model = TransformerModel(\n",
        "                input_dim=self.input_dim,\n",
        "                d_model=hyperparams['d_model'],\n",
        "                nhead=hyperparams['nhead'],\n",
        "                num_layers=hyperparams['num_layers'],\n",
        "                dim_feedforward=hyperparams['dim_feedforward'],\n",
        "                dropout=hyperparams['dropout']\n",
        "            ).to(self.device)\n",
        "\n",
        "            criterion = nn.MSELoss()\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=hyperparams['learning_rate'])\n",
        "\n",
        "            best_val_loss = float('inf')\n",
        "            patience = 3\n",
        "            patience_counter = 0\n",
        "\n",
        "            for epoch in range(epochs):\n",
        "                model.train()\n",
        "                for batch_x, batch_y in self.train_loader:\n",
        "                    batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
        "                    optimizer.zero_grad()\n",
        "                    output = model(batch_x)\n",
        "                    loss = criterion(output, batch_y)\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                model.eval()\n",
        "                val_loss = 0\n",
        "                with torch.no_grad():\n",
        "                    for batch_x, batch_y in self.val_loader:\n",
        "                        batch_x, batch_y = batch_x.to(self.device), batch_y.to(self.device)\n",
        "                        output = model(batch_x)\n",
        "                        val_loss += criterion(output, batch_y).item()\n",
        "\n",
        "                val_loss /= len(self.val_loader)\n",
        "\n",
        "                if val_loss < best_val_loss:\n",
        "                    best_val_loss = val_loss\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                    if patience_counter >= patience:\n",
        "                        break\n",
        "\n",
        "            return best_val_loss\n",
        "        except Exception as e:\n",
        "            print(f\"Error during model evaluation: {str(e)}\")\n",
        "            return float('inf')\n",
        "\n",
        "    def slime_mould_algorithm(self, N=20, max_iter=30):\n",
        "        \"\"\"\n",
        "        Modified SMA for transformer hyperparameter optimization.\n",
        "        \"\"\"\n",
        "        dim = len(self.param_bounds)  # Number of hyperparameters\n",
        "        lb = np.zeros(dim)  # Lower bound is 0 for all parameters\n",
        "        ub = np.ones(dim)   # Upper bound is 1 for all parameters\n",
        "\n",
        "        # Define objective function for the algorithm\n",
        "        def obj_func(position):\n",
        "            hyperparams = self.decode_solution(position)\n",
        "            return self.evaluate_model(hyperparams)\n",
        "\n",
        "        # Initialize population\n",
        "        population = np.random.uniform(lb, ub, (N, dim))\n",
        "        fitness = np.apply_along_axis(obj_func, 1, population)\n",
        "\n",
        "        # Initialize best solution\n",
        "        best_idx = np.argmin(fitness)\n",
        "        best_position = population[best_idx].copy()\n",
        "        best_fitness = fitness[best_idx]\n",
        "\n",
        "        for t in range(max_iter):\n",
        "            print(f\"Iteration {t + 1}/{max_iter}, Best Loss: {best_fitness:.6f}\")\n",
        "\n",
        "            # Rank population and assign weights\n",
        "            sorted_indices = np.argsort(fitness)\n",
        "            population = population[sorted_indices]\n",
        "            fitness = fitness[sorted_indices]\n",
        "\n",
        "            # Update best position\n",
        "            if fitness[0] < best_fitness:\n",
        "                best_position = population[0].copy()\n",
        "                best_fitness = fitness[0]\n",
        "\n",
        "            # Calculate weights\n",
        "            W = 1 + np.log(1 + (fitness[-1] - fitness) / (fitness[-1] - fitness[0] + 1e-10))\n",
        "\n",
        "            # Update positions\n",
        "            for i in range(N):\n",
        "                r = np.random.rand()\n",
        "                vb = np.random.uniform(-1, 1)\n",
        "                vc = np.random.uniform(0, 1)\n",
        "                if r < vc:\n",
        "                    # Exploitation phase\n",
        "                    new_position = population[0] + vb * (W[i] * (population[i] - population[0]))\n",
        "                else:\n",
        "                    # Exploration phase\n",
        "                    new_position = np.random.uniform(lb, ub, dim)\n",
        "\n",
        "                # Boundary control\n",
        "                population[i] = np.clip(new_position, lb, ub)\n",
        "\n",
        "            # Evaluate fitness of updated population\n",
        "            fitness = np.apply_along_axis(obj_func, 1, population)\n",
        "\n",
        "        return self.decode_solution(best_position), best_fitness\n",
        "\n",
        "# Generate sample data\n",
        "def generate_sample_data(num_samples=1000, seq_length=24, input_dim=5):\n",
        "    X = np.random.randn(num_samples, seq_length, input_dim)\n",
        "    y = np.sum(X[:, -1, :], axis=1)\n",
        "    return torch.FloatTensor(X), torch.FloatTensor(y)\n",
        "\n"
      ],
      "metadata": {
        "id": "p4hR99131XGl"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "train_loader = train_loader\n",
        "val_loader = test_loader\n",
        "input_dim = X_train.shape[2]\n",
        "optimizer = HyperparameterOptimizer(train_loader, val_loader, input_dim, device)\n",
        "\n",
        "print(\"Starting hyperparameter optimization...\")\n",
        "start_time = time.time()\n",
        "\n",
        "best_hyperparams, best_loss = optimizer.slime_mould_algorithm(\n",
        "    N=10,\n",
        "    max_iter=5\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"\\nOptimization completed!\")\n",
        "print(f\"Time taken: {(end_time - start_time)/60:.2f} minutes\")\n",
        "print(\"\\nBest Hyperparameters:\")\n",
        "for param, value in best_hyperparams.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "print(f\"Best Validation Loss: {best_loss:.6f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHMHWZSN1Yjh",
        "outputId": "40a25f35-1a5b-4043-8810-09c6996ed7a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Starting hyperparameter optimization...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1/5, Best Loss: 0.009315\n",
            "Iteration 2/5, Best Loss: 0.009315\n",
            "Iteration 3/5, Best Loss: 0.009315\n",
            "Iteration 4/5, Best Loss: 0.009315\n",
            "Iteration 5/5, Best Loss: 0.009315\n",
            "\n",
            "Optimization completed!\n",
            "Time taken: 2.11 minutes\n",
            "\n",
            "Best Hyperparameters:\n",
            "d_model: 164\n",
            "nhead: 4\n",
            "num_layers: 1\n",
            "dim_feedforward: 151\n",
            "dropout: 0.022613644455269033\n",
            "learning_rate: 0.003320770274556317\n",
            "Best Validation Loss: 0.009315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GvS1B4nF2EiI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}